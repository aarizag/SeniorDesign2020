{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToAscendingOrder(newList2):\n",
    "    #print(\"# puts list in ascending order\")\n",
    "    index_OfGreatest = 0\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(len(newList2)):\n",
    "        # Find index of greatest value\n",
    "        for j in range(len(newList2) - counter):\n",
    "            if(newList2[index_OfGreatest][1] < newList2[j][1]):\n",
    "                index_OfGreatest = j\n",
    "\n",
    "        # use index found to switch greatest index with (last - counter)\n",
    "        if(i != 0):\n",
    "            temp = newList2[index_OfGreatest]\n",
    "            newList2[index_OfGreatest] = newList2[len(newList2) - (counter + 1)]\n",
    "            newList2[len(newList2) - counter] = temp\n",
    "\n",
    "        # increase the counter and reset index of greatest to 0\n",
    "        counter += 1\n",
    "        index_OfGreatest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.196152422706632\n"
     ]
    }
   ],
   "source": [
    "## Euclidean Distance\n",
    "#  - distance between two vectors\n",
    "import math\n",
    "def euclidean_distance(u, v):\n",
    "    summation = 0\n",
    "    for i in range(len(u)):\n",
    "        # (u1 - v1)^ 2\n",
    "        summation += ((u[i] - v[i]) * (u[i] - v[i]))\n",
    "    # squareroot result of summation\n",
    "    euclidean_distance = math.sqrt(summation)\n",
    "    return euclidean_distance\n",
    "# Example       \n",
    "print(euclidean_distance([1,2,3], [4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Done loading Google's Pre-Trained Word2Vec model\n"
     ]
    }
   ],
   "source": [
    "## Load Google's Pre-Trained Dataset\n",
    "##\n",
    "\n",
    "import gensim.models.word2vec as word2vec\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Google's Pre-Trained Data Set\n",
    "from gensim.models import KeyedVectors\n",
    "file_directory = '/Users/norinchea/Desktop/SeniorProject/wordEmbedding/Google/GoogleNews-vectors-negative300-SLIM.bin'\n",
    "# Googles Pre-trained data set has 300 futures\n",
    "model = KeyedVectors.load_word2vec_format(file_directory, binary=True)\n",
    "\n",
    "print(\"## Done loading Google's Pre-Trained Word2Vec model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1_normalized = 'school supply set kit' \n",
    "sentence_2_normalized = 'school equipment supply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'equipment', 'supply']\n"
     ]
    }
   ],
   "source": [
    "## Tokenize both normalized sentences being compared\n",
    "##\n",
    "from nltk.tokenize import word_tokenize as tokenize_sentence\n",
    "\n",
    "# before tokenizing a sentence, the sentence has to be normalized\n",
    "sentence_1_tokenized = tokenize_sentence(sentence_1_normalized)\n",
    "sentence_2_tokenized = tokenize_sentence(sentence_2_normalized)\n",
    "\n",
    "print(sentence_2_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word embedding\n",
    "##\n",
    "# Using Google's pre-train dataset, convert every word in the tokenized sentence into its \n",
    "# position coordinates in a 300 dimension vector space\n",
    "def word_embedding(tokenized_sentence):\n",
    "    list_wordembedding = []\n",
    "    for token in tokenized_sentence:\n",
    "        list_wordembedding.append(model[token]) \n",
    "    return list_wordembedding\n",
    "        \n",
    "# word_embedding() takes in a tokenized sentence \n",
    "# this function will return a list of list containing\n",
    "# the vector position of every word in a sentece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter = two normalized sentences\n",
    "def list_vectorPosition(tokenized_sentence1, tokenized_sentence2):\n",
    "    # list at index 0 = sentence 1\n",
    "    # list at index 1 = sentence 2\n",
    "    list1 = []\n",
    "    # the vector position of every word in a sentece\n",
    "    sentence1_vector_position = word_embedding(tokenized_sentence1) # vector position for every word in sentence 1\n",
    "    sentence2_vector_position = word_embedding(tokenized_sentence2) # vector position for every word in sentence 1\n",
    "    list1.append(sentence1_vector_position)\n",
    "    list1.append(sentence2_vector_position)\n",
    "    return list1\n",
    "\n",
    "#list_vectorPosition returns a (list) containing a (list) of (list with 300 values).\n",
    "#list_vectorPosition[0] vector positions for sentence 1\n",
    "#list_vectorPosition[1] vector positions for sentence 2\n",
    "#list_vectorPosition[0][i] returns a list with vector position (300 entries) of word at i\n",
    "\n",
    "list1 = list_vectorPosition(sentence_1_tokenized, sentence_2_tokenized)\n",
    "\n",
    "# print(str(len(list1)) + \" list1\")\n",
    "# print(str(len(list1[0])) + \" list1[0] sentence 1\" ) # sentence 1\n",
    "# print(str(len(list1[0][1])) + \" list1[0][1] vector position for the first word in sentence 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def compare(tokenized_sentence1, tokenized_sentence2, list_of_vector_position):\n",
    "    # index 0 = sentence 1\n",
    "    # index 1 = sentence 2\n",
    "    compareFrom = tokenized_sentence1\n",
    "    compareTo = tokenized_sentence2\n",
    "    compareFrom_vector = 0 #list_of_vector_position[0]\n",
    "    compareTo_vector = 1 #list_of_vector_position[1]\n",
    "    if (len(tokenized_sentence1) < len(tokenized_sentence2)):\n",
    "        compareFrom = tokenized_sentence2\n",
    "        compareTo = tokenized_sentence1\n",
    "        compareFrom_vector = 1 # list_of_vector_position[1]\n",
    "        compareTo_vector = 0 # list_of_vector_position[0]\n",
    "    \n",
    "    index_of_most_similar = 0 # j\n",
    "    distance_of_most_similar = 10000\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range( len(list_of_vector_position[compareFrom_vector]) ):\n",
    "        for j in range( len(list_of_vector_position[compareTo_vector]) ):\n",
    "            current_distance = euclidean_distance(list_of_vector_position[compareFrom_vector][i], list_of_vector_position[compareTo_vector][j])\n",
    "            \n",
    "            if(distance_of_most_similar > current_distance):\n",
    "                index_of_most_similar = j\n",
    "                distance_of_most_similar = current_distance\n",
    "                \n",
    "        results.append( [compareFrom[i], compareTo[index_of_most_similar], distance_of_most_similar] )\n",
    "        index_of_most_similar = 0\n",
    "        distance_of_most_similar = 10000\n",
    "        \n",
    "    return results\n",
    "    \n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_1_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['school', 'school', 0.0],\n",
       " ['supply', 'supply', 0.0],\n",
       " ['set', 'school', 3.0438728091451535],\n",
       " ['kit', 'equipment', 3.4905076674588074]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = compare(sentence_1_tokenized, sentence_2_tokenized, list1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n"
     ]
    }
   ],
   "source": [
    "def removeDistanceScore(list_results):\n",
    "    newList = []\n",
    "    for list in list_results:\n",
    "        newList.append(list[:-1])\n",
    "    return newList\n",
    "results_NoScore = removeDistanceScore(results)\n",
    "print(results_NoScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'school supply set kit'\n",
    "s2 = 'school equipment supply'\n",
    "\n",
    "def compareResults(sentence_1_normalized, sentence_2_normailzed):\n",
    "    # tokenize normalized sentences\n",
    "    s1_t = tokenize_sentence(sentence_1_normalized) # tokenize sentence 1\n",
    "    s2_t = tokenize_sentence(sentence_2_normailzed) # tokenize sentence 2\n",
    "\n",
    "    list1_final = list_vectorPosition(s1_t, s2_t) # list with vector positions of every word in both sentences\n",
    "    \n",
    "    results_Final = compare(s1_t, s2_t, list1_final) # return list with nearest neighbors and distance score\n",
    "    \n",
    "    results__final_NoScore = removeDistanceScore(results_Final) # remove score list from results\n",
    "    \n",
    "    return results__final_NoScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n"
     ]
    }
   ],
   "source": [
    "nearestNeighbors = compareResults(s1, s2)\n",
    "print( nearestNeighbors )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print list for easier readabilty\n",
    "def printList(lists):\n",
    "    for current_list in lists:\n",
    "        print(current_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "- Sentences being compared - \n",
      "Sentence 1: school supply set kit\n",
      "Sentence 2: school equipment supply\n",
      "------------------------------------------------------------------------\n",
      "- Similarity Percentage between each pair - \n",
      "['school', 'school', 100.0]\n",
      "['supply', 'supply', 100.0]\n",
      "['set', 'school', 72.72727272727273]\n",
      "['kit', 'equipment', 87.5]\n",
      "------------------------------------------------------------------------\n",
      "- Average Percentage - \n",
      "90.05681818181819% Similarity\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import script that find similarity percentage\n",
    "import wordNet\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"- Sentences being compared - \")\n",
    "print(\"Sentence 1: \" + s1)\n",
    "print(\"Sentence 2: \" + s2)\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"- Similarity Percentage between each pair - \")\n",
    "list_wordNet_results = wordNet.results(nearestNeighbors)\n",
    "#print(list_wordNet_results)\n",
    "printList(list_wordNet_results)\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"- Average Percentage - \")\n",
    "averagePercentage = wordNet.average_percentage(nearestNeighbors)\n",
    "print(str(averagePercentage) + \"% Similarity\")\n",
    "print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Using the UNSPSC and eCOMM from our manual comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our UNSPSC from our manual comparisons\n",
    "import pandas as pd\n",
    "\n",
    "unspsc_column = 11\n",
    "\n",
    "unspsc = pd.read_excel('Unspec_List_normalized.xlsx').iloc[:,unspsc_column]\n",
    "ecomm = pd.read_excel('County_List_normalized.xlsx').iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       elevators escalators build type\n",
       "1                     food process can equipment supply\n",
       "2               furniture health care hospital facility\n",
       "3                 mattress manufacture machinery supply\n",
       "4                                   educational service\n",
       "5                           paper office print shop use\n",
       "6                                voice response systems\n",
       "7                   refrigeration equipment accessories\n",
       "8                        build construction service new\n",
       "9                                    bookbinding supply\n",
       "10               build structure fabricate prefabricate\n",
       "11                          computer accessories supply\n",
       "12    cutlery dish flatware glassware trays utensils...\n",
       "13                      plumb equipment fixtures supply\n",
       "14    concrete metal culverts pile septic tank accessor\n",
       "15                   miscellaneous professional service\n",
       "16               security fire safety emergency service\n",
       "17     equipment maintenance recondition repair service\n",
       "18                              school equipment supply\n",
       "19                               miscellaneous products\n",
       "20                                            shoe boot\n",
       "21                                            tire tube\n",
       "22                                        human service\n",
       "23     equipment maintenance recondition repair service\n",
       "24                  coolers drink water water fountains\n",
       "25    mass transportation rail vehicle part accessories\n",
       "26                                            shoe boot\n",
       "27                     television equipment accessories\n",
       "28             test apparatus instrument electrical ele\n",
       "29                              police equipment supply\n",
       "30            library archival equipment machine supply\n",
       "31                       nursery stock equipment supply\n",
       "32    publications audiovisual materials prepare mat...\n",
       "33                     water wastewater treat chemicals\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecomm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         drink coolers\n",
       "1                   elevator front installation service\n",
       "2                                             elevators\n",
       "3                                      can bottle label\n",
       "4                               computer printout paper\n",
       "5                  manufacture equipment repair service\n",
       "6             manufacture equipment maintenance service\n",
       "7                                              bind kit\n",
       "8                                 school supply set kit\n",
       "9                 build consent process support service\n",
       "10    professional errors omissions liability insura...\n",
       "11         development consent approval process service\n",
       "12    build consent permit engineer peer review service\n",
       "13            job search skills instructional materials\n",
       "14                                            fireworks\n",
       "15                                      artificial turf\n",
       "16                                      lottery machine\n",
       "17                                          bridge rail\n",
       "18                                            mast boot\n",
       "19                                      cloud apparatus\n",
       "20                                      police vehicles\n",
       "21                             police security shotguns\n",
       "22                                       police uniform\n",
       "23                             backup archival software\n",
       "24       library compact disc audio cassette displayers\n",
       "25                                      nursery service\n",
       "26            laboratory wastewater treatment equipment\n",
       "27                          pool spa whirlpool chemical\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unspsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school equipment supply\n",
      "----------------------------------------------------\n",
      "['artificial turf', 22.222222222222218]\n",
      "['artificial turf', 22.222222222222218]\n",
      "['backup archival software', 24.224664224664224]\n",
      "['fireworks', 26.19047619047619]\n",
      "['professional errors omissions liability insurance contract', 34.99245852187028]\n",
      "['police uniform', 38.09523809523809]\n",
      "['job search skills instructional materials', 46.743589743589745]\n",
      "['build consent permit engineer peer review service', 50.692450406736114]\n",
      "['elevators', 54.131652661064415]\n",
      "['build consent process support service', 54.56943056943057]\n",
      "['development consent approval process service', 54.56943056943057]\n",
      "['drink coolers', 57.214680744092504]\n",
      "['library compact disc audio cassette displayers', 57.30957767722473]\n",
      "['computer printout paper', 57.95454545454546]\n",
      "['bind kit', 58.18627450980392]\n",
      "['police vehicles', 60.0]\n",
      "['laboratory wastewater treatment equipment', 63.62179487179487]\n",
      "['lottery machine', 63.80952380952382]\n",
      "['police security shotguns', 63.888888888888886]\n",
      "['cloud apparatus', 64.06565656565657]\n",
      "['mast boot', 64.32748538011695]\n",
      "['manufacture equipment maintenance service', 68.51190476190476]\n",
      "['can bottle label', 74.43850267379679]\n",
      "['manufacture equipment repair service', 75.89285714285714]\n",
      "['bridge rail', 76.66666666666667]\n",
      "['elevator front installation service', 77.59115884115884]\n",
      "['nursery service', 78.57142857142857]\n",
      "['school supply set kit', 90.05681818181819]\n"
     ]
    }
   ],
   "source": [
    "eCOMM_Line = ecomm.iloc[18]\n",
    "print(eCOMM_Line)\n",
    "print(\"----------------------------------------------------\")\n",
    "def percentage_similarity(eCOMM_line_, unspsc_):\n",
    "    list_t = []\n",
    "    for i in range( len(unspsc_)):\n",
    "        #print(unspsc.iloc[i])\n",
    "        current_result = compareResults(eCOMM_line_, unspsc_.iloc[i]) # compare a ecomm line to the current line from UNSPSC\n",
    "        newlist = [unspsc_.iloc[i], wordNet.average_percentage(current_result)]\n",
    "        list_t.append( newlist )\n",
    "    return list_t \n",
    "    \n",
    "sim_percentage1 = percentage_similarity(eCOMM_Line, unspsc)\n",
    "listToAscendingOrder(sim_percentage1)\n",
    "\n",
    "printList(sim_percentage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water wastewater treat chemicals\n",
      "--------------------------------------------\n",
      "['artificial turf', 20.833333333333332]\n",
      "['artificial turf', 20.833333333333332]\n",
      "['backup archival software', 26.726190476190478]\n",
      "['police security shotguns', 28.644688644688646]\n",
      "['police uniform', 28.644688644688646]\n",
      "['elevators', 34.791666666666664]\n",
      "['police vehicles', 35.13819513819514]\n",
      "['professional errors omissions liability insurance contract', 36.6015466015466]\n",
      "['cloud apparatus', 40.38461538461539]\n",
      "['mast boot', 42.24089635854341]\n",
      "['can bottle label', 42.69230769230769]\n",
      "['bind kit', 43.86904761904761]\n",
      "['lottery machine', 44.09090909090909]\n",
      "['bridge rail', 44.107142857142854]\n",
      "['build consent permit engineer peer review service', 44.982993197278915]\n",
      "['job search skills instructional materials', 45.22144522144522]\n",
      "['manufacture equipment repair service', 45.84478021978022]\n",
      "['nursery service', 45.84478021978022]\n",
      "['elevator front installation service', 46.485805860805854]\n",
      "['development consent approval process service', 46.88095238095238]\n",
      "['manufacture equipment maintenance service', 48.07692307692308]\n",
      "['library compact disc audio cassette displayers', 50.22058823529411]\n",
      "['build consent process support service', 50.52197802197802]\n",
      "['school supply set kit', 56.42857142857142]\n",
      "['fireworks', 64.12990196078431]\n",
      "['drink coolers', 67.28632478632478]\n",
      "['laboratory wastewater treatment equipment', 68.66515837104072]\n",
      "['computer printout paper', 71.71703296703296]\n"
     ]
    }
   ],
   "source": [
    "eCOMM_Line1 = ecomm.iloc[33]\n",
    "print(eCOMM_Line1)\n",
    "print(\"--------------------------------------------\")\n",
    "sim_percentage2 = percentage_similarity(eCOMM_Line1, unspsc)\n",
    "listToAscendingOrder(sim_percentage2)\n",
    "printList(sim_percentage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equipment maintenance recondition repair service\n",
      "--------------------------------------------\n",
      "['backup archival software', 21.571428571428573]\n",
      "['backup archival software', 21.571428571428573]\n",
      "['artificial turf', 21.714285714285715]\n",
      "['fireworks', 24.333333333333332]\n",
      "['police uniform', 31.823313940960997]\n",
      "['elevators', 38.630718954248366]\n",
      "['bind kit', 40.15597147950089]\n",
      "['drink coolers', 44.53781512605042]\n",
      "['cloud apparatus', 44.621848739495796]\n",
      "['computer printout paper', 45.84162895927602]\n",
      "['can bottle label', 46.47899159663865]\n",
      "['laboratory wastewater treatment equipment', 46.815018315018314]\n",
      "['police vehicles', 48.63003663003663]\n",
      "['police security shotguns', 50.53759965524672]\n",
      "['lottery machine', 50.67032967032967]\n",
      "['professional errors omissions liability insurance contract', 55.83039896120391]\n",
      "['mast boot', 56.12121212121211]\n",
      "['library compact disc audio cassette displayers', 56.66122004357299]\n",
      "['build consent permit engineer peer review service', 59.12724063984568]\n",
      "['bridge rail', 59.643962848297214]\n",
      "['job search skills instructional materials', 71.18764568764568]\n",
      "['school supply set kit', 71.67460317460318]\n",
      "['elevator front installation service', 72.33699633699634]\n",
      "['development consent approval process service', 74.81225296442688]\n",
      "['nursery service', 74.81225296442688]\n",
      "['build consent process support service', 79.89233954451346]\n",
      "['manufacture equipment maintenance service', 82.12454212454212]\n",
      "['manufacture equipment repair service', 90.47619047619048]\n"
     ]
    }
   ],
   "source": [
    "eCOMM_Line2 = ecomm.iloc[23]\n",
    "print(eCOMM_Line2)\n",
    "print(\"--------------------------------------------\")\n",
    "sim_percentage3 = percentage_similarity(eCOMM_Line2, unspsc)\n",
    "listToAscendingOrder(sim_percentage3)\n",
    "printList(sim_percentage3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eCOMM_Line = ecomm.iloc[18]\n",
    "# print(eCOMM_Line)\n",
    "# print(\"----------------------------------------------------\")\n",
    "\n",
    "# list_t = []\n",
    "# for i in range( len(unspsc)):\n",
    "#     #print(unspsc.iloc[i])\n",
    "#     current_result = compareResults(eCOMM_Line, unspsc.iloc[i]) # compare a ecomm line to the current line from UNSPSC\n",
    "#     newlist = [unspsc.iloc[i], wordNet.average_percentage(current_result)]\n",
    "#     list_t.append( newlist )\n",
    "    \n",
    "# #print(list_t)    \n",
    "# printList(list_t)\n",
    "\n",
    "\n",
    "# print(list_) # 13 15\n",
    "# index = 13\n",
    "# print(unspsc.iloc[index])\n",
    "# current_result = compareResults(eCOMM_Line, unspsc.iloc[index])\n",
    "# #print(current_result)\n",
    "# print(wordNet.results(current_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import wordnet\n",
    "# #library compact disc audio cassette displayers\n",
    "# word1 = wordnet.synsets(\"service\") \n",
    "# word2 = wordnet.synsets(\"displayers\") \n",
    "# print(word1)\n",
    "# print(\"---------------------\")\n",
    "# print(word2)\n",
    "\n",
    "# if (len(word2) == 0):\n",
    "#     print(\"It is zero\")\n",
    "#percent_most_similar = word1[0].wup_similarity(word2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 24\n",
    "# unspsc_sentence = unspsc.iloc[index]\n",
    "# print(eCOMM_Line)\n",
    "# print(unspsc_sentence)\n",
    "\n",
    "# current_result = compareResults(eCOMM_Line, unspsc_sentence)\n",
    "\n",
    "# print(current_result)\n",
    "\n",
    "# newlist = [unspsc_sentence, wordNet.average_percentage(current_result)]\n",
    "# print(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
