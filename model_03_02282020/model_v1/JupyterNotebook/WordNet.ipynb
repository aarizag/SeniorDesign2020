{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "## Assuming our model to determine which words will be comapred to each other works\n",
    "# s1 = [\"president\", \"greets\", \"press\", \"chicago\"]\n",
    "# s2 = [\"leader\", \"speaks\", \"media\", \"illinois\"]\n",
    "\n",
    "#list1 = [['president', 'leader'], ['greets', 'speaks'], ['press', 'media'], ['chicago', 'illinois']]\n",
    "#list1 = [['president', 'leader'], ['greets', 'speaks'], ['press', 'media'], ['chicago', 'illinois']]\n",
    "\n",
    "list1 = [['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# find similarity percentange between two words\n",
    "# takes in two list as a parameter, each list has syns of the current word\n",
    "def similarity_percentage(word1, word2):\n",
    "    percent_most_similar = word1[0].wup_similarity(word2[0])\n",
    "\n",
    "    for i in range(len(word1)):\n",
    "        word1_syn = word1[i]\n",
    "        for j in range(len(word2)):\n",
    "            word2_syn = word2[j]\n",
    "            wupSimilar = word1_syn.wup_similarity(word2_syn)\n",
    "            if (wupSimilar is not None or wupSimilar != None):\n",
    "                if (percent_most_similar < wupSimilar):\n",
    "                    percent_most_similar = wupSimilar\n",
    "                #print( str(wupSimilar * 100) + \"% similarity - \" + str(word1[i]) + \" and \" + str(word2[j]) )\n",
    "        #print(\"-------------------------------------------------------------------\")\n",
    "    return percent_most_similar\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Percentage for each pair\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['school', 'school', 100.0],\n",
       " ['supply', 'supply', 100.0],\n",
       " ['set', 'school', 72.72727272727273],\n",
       " ['kit', 'equipment', 87.5]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## takes in a list of list containing what two words are similar\n",
    "## Example: \n",
    "## [['president', 'leader'], ['greets', 'speaks'], ['press', 'media'], ['chicago', 'illinois']]   \n",
    "def results(list_of_lists):\n",
    "    results = []\n",
    "    for i in range(len(list_of_lists)):\n",
    "        word1_s1 = wordnet.synsets(list_of_lists[i][0]) \n",
    "        word2_s2 = wordnet.synsets(list_of_lists[i][1]) \n",
    "        #print(word1_s1)\n",
    "        #print(word2_s2)\n",
    "        percentage = similarity_percentage(word1_s1, word2_s2)\n",
    "        results.append( [list_of_lists[i][0], list_of_lists[i][1] , percentage * 100] )\n",
    "    return results\n",
    "\n",
    "\n",
    "# similarity percentage\n",
    "print(\"Similarity Percentage for each pair\")\n",
    "print(\"-----------------------------------\")\n",
    "## we can also try to improve by also comparing the lemma names\n",
    "## ['Word 1', 'Word 2', similarity % between words 1 & 2]\n",
    "results(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['elevators', 'elevator'], ['escalators', 'elevator'], ['build', 'front'], ['type', 'front']]\n"
     ]
    }
   ],
   "source": [
    "list3 = [['elevators', 'elevator'], ['escalators', 'elevator'], ['build', 'front'], ['type', 'front']]\n",
    "print(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elevators', 'elevator', 100.0],\n",
       " ['escalators', 'elevator', 58.82352941176471],\n",
       " ['build', 'front', 53.333333333333336],\n",
       " ['type', 'front', 66.66666666666666]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'hi', 100.0]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4 = [['hello', 'hi']]\n",
    "results(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test = wordnet.synsets('hey')\n",
    "#[['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n",
    "#wupSimilar = word1_syn.wup_similarity(word2_syn)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
