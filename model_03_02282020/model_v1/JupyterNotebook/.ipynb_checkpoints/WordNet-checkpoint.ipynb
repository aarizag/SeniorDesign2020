{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "## Assuming our model to determine which words will be comapred to each other works\n",
    "# s1 = [\"president\", \"greets\", \"press\", \"chicago\"]\n",
    "# s2 = [\"leader\", \"speaks\", \"media\", \"illinois\"]\n",
    "\n",
    "#list1 = [['president', 'leader'], ['greets', 'speaks'], ['press', 'media'], ['chicago', 'illinois']]\n",
    "#list1 = [['president', 'leader'], ['greets', 'speaks'], ['press', 'media'], ['chicago', 'illinois']]\n",
    "\n",
    "list1 = [['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# find similarity percentange between two words\n",
    "# takes in two list as a parameter, each list has syns of the current word\n",
    "def similarity_percentage(word1, word2):\n",
    "    percent_most_similar = word1[0].wup_similarity(word2[0])\n",
    "\n",
    "    for i in range(len(word1)):\n",
    "        word1_syn = word1[i]\n",
    "        for j in range(len(word2)):\n",
    "            word2_syn = word2[j]\n",
    "            wupSimilar = word1_syn.wup_similarity(word2_syn)\n",
    "            if (wupSimilar is not None or wupSimilar != None):\n",
    "                if (percent_most_similar < wupSimilar):\n",
    "                    percent_most_similar = wupSimilar\n",
    "                #print( str(wupSimilar * 100) + \"% similarity - \" + str(word1[i]) + \" and \" + str(word2[j]) )\n",
    "        #print(\"-------------------------------------------------------------------\")\n",
    "    return percent_most_similar\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Percentage for each pair\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['school', 'school', 100.0],\n",
       " ['supply', 'supply', 100.0],\n",
       " ['set', 'school', 72.72727272727273],\n",
       " ['kit', 'equipment', 87.5]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## takes in a list of list containing what two words are similar\n",
    "## Example: \n",
    "## [['president', 'leader'], ['greets', 'speaks'], ['press', 'media'], ['chicago', 'illinois']]   \n",
    "def results(list_of_lists):\n",
    "    results = []\n",
    "    for i in range(len(list_of_lists)):\n",
    "        word1_s1 = wordnet.synsets(list_of_lists[i][0]) \n",
    "        word2_s2 = wordnet.synsets(list_of_lists[i][1]) \n",
    "        #print(word1_s1)\n",
    "        #print(word2_s2)\n",
    "        percentage = similarity_percentage(word1_s1, word2_s2)\n",
    "        results.append( [list_of_lists[i][0], list_of_lists[i][1] , percentage * 100] )\n",
    "    return results\n",
    "\n",
    "\n",
    "# similarity percentage\n",
    "print(\"Similarity Percentage for each pair\")\n",
    "print(\"-----------------------------------\")\n",
    "## we can also try to improve by also comparing the lemma names\n",
    "## ['Word 1', 'Word 2', similarity % between words 1 & 2]\n",
    "results(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['elevators', 'elevator'], ['escalators', 'elevator'], ['build', 'front'], ['type', 'front']]\n"
     ]
    }
   ],
   "source": [
    "list3 = [['elevators', 'elevator'], ['escalators', 'elevator'], ['build', 'front'], ['type', 'front']]\n",
    "print(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elevators', 'elevator', 100.0],\n",
       " ['escalators', 'elevator', 58.82352941176471],\n",
       " ['build', 'front', 53.333333333333336],\n",
       " ['type', 'front', 66.66666666666666]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1cf1a4aa83a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'maint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ecba93a40690>\u001b[0m in \u001b[0;36mresults\u001b[0;34m(list_of_lists)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(word1_s1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(word2_s2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpercentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_percentage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2_s2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist_of_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bbc5dcabd201>\u001b[0m in \u001b[0;36msimilarity_percentage\u001b[0;34m(word1, word2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# takes in two list as a parameter, each list has syns of the current word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimilarity_percentage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpercent_most_similar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwup_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "list4 = [['hello', 'hi']]\n",
    "results(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test = wordnet.synsets('hey')\n",
    "#[['school', 'school'], ['supply', 'supply'], ['set', 'school'], ['kit', 'equipment']]\n",
    "#wupSimilar = word1_syn.wup_similarity(word2_syn)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
