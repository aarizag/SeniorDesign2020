{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from xlrd import open_workbook\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import pprint\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from xlrd import open_workbook\n",
    "import json\n",
    "from gensim import similarities\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "       \n",
    "unspec_df = pd.read_excel('ignore/UNSPSC English v220601 project.xlsx','Sheet1', index_col=None, na_values=['NA'])\n",
    "unspec = unspec_df.drop(['Family Definition','Family','Family Title','Segment Title','Segment Definition','Segment','Version','Key','Synonym','Acronym'],axis = 1)\n",
    "cols = ['Class Title','Class Definition']\n",
    "cols2 =['Commodity Title','Commodity Definition']\n",
    "col3 = ['class','commodity']\n",
    "unspec[\"class\"] = unspec[cols].apply(lambda row: ','.join(row.values.astype(str)), axis=1)\n",
    "unspec[\"commodity\"] = unspec[cols2].apply(lambda row: ','.join(row.values.astype(str)), axis=1)\n",
    "unspec[\"combine\"]= unspec[col3].apply(lambda row: ', '.join(row.values.astype(str)),axis=1)\n",
    "unspec[\"combine\"]=[row.replace('nan','')for row in unspec[\"combine\"]]\n",
    "unspec2 = unspec.drop(['Class','Class Title','Class Definition','Commodity Title','Commodity Definition','class','commodity'],axis=1)\n",
    "unspec2=unspec2.rename(columns={\"Commodity\":\"level_1\"})\n",
    "nums = unspec2['level_1'].tolist()"
=======
   "outputs": [],
   "source": [
    "        \n",
    "unspec_df = pd.read_excel('ignore/UNSPSC English v220601 project.xlsx','Sheet1', index_col=None, na_values=['NA'])\n",
    "unspec = unspec_df.drop(['Family Definition','Family','Family Title','Segment Title','Segment Definition','Segment','Version','Key','Synonym','Acronym'],axis = 1)\n",
    "cols = ['Class Title','Class Definition']\n",
    "cols2 =['Commodity Title','Commodity Definition']\n",
    "unspec[\"class\"] = unspec[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "unspec[\"commodity\"] = unspec[cols2].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "#unspec[\"commodity\"]=[row.replace(' ',',') for row in unspec[\"commodity\"]]\n",
    "#unspec[\"class\"]=[row.replace(' ',',') for row in unspec[\"class\"]]\n",
    "unspec2 = unspec.drop(['Class','Class Title','Class Definition','Commodity Title','Commodity Definition'],axis=1)\n",
    "unspec2=unspec2.rename(columns={\"Commodity\":\"level_1\"})\n",
    "nums = unspec2['level_1'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df = pd.read_excel('ignore/eCAPS_COMM_11072019.xlsx','COMM_CLS', index_col=None, na_values=['NA'])\n",
    "county_df2 = pd.read_excel('ignore/eCAPS_COMM_11072019.xlsx','COMM_ITM', index_col=None, na_values=['NA'])\n",
    "county_df.drop(['COMM_GP','COMM_DET','ACT_INACT_FL','NAICS_CD'],axis=1)\n",
    "county_df2.drop(['COMM_GP','COMM_DET','ACT_INACT_FL','NAICS_CD'],axis=1)\n",
    "countyresult = pd.merge(county_df,county_df2,on='COMM_CLS')\n",
    "cr = countyresult.drop(['DSCR_EXT_y','DSCR_EXT_DV_x','DSCR_EXT_x','COMM_DSCR_UP_x','COMM_CD_x','COMM_ITM_x','COMM_GP_x','COMM_DET_x','ACT_INACT_FL_x','NAICS_CD_x','COMM_DET_y','COMM_GP_y','COMM_DET_y','ACT_INACT_FL_y','NAICS_CD_y','COMM_DSCR_UP_y','DSCR_EXT_DV_y'],axis=1)\n",
    "cr2 = cr.rename(columns={\"KEYWD_x\":\"class\",\"KEYWD_y\":\"commodity\",\"COMM_CD_y\":\"level_1\"})\n",
    "#cr2[\"commodity\"]=[row.replace(' ',',') for row in cr2[\"commodity\"]]\n",
    "#cr2[\"class\"]=[row.replace(' ',',') for row in cr2[\"class\"]]\n"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df = pd.read_excel('ignore/eCAPS_COMM_11072019.xlsx','COMM_CLS', index_col=None, na_values=['NA'])\n",
    "county_df2 = pd.read_excel('ignore/eCAPS_COMM_11072019.xlsx','COMM_ITM', index_col=None, na_values=['NA'])\n",
    "county_df.drop(['COMM_GP','COMM_DET','ACT_INACT_FL','NAICS_CD'],axis=1)\n",
    "county_df2.drop(['COMM_GP','COMM_DET','ACT_INACT_FL','NAICS_CD'],axis=1)\n",
    "countyresult = pd.merge(county_df,county_df2,on='COMM_CLS')\n",
    "cr = countyresult.drop(['DSCR_EXT_y','DSCR_EXT_DV_x','DSCR_EXT_x','COMM_DSCR_UP_x','COMM_CD_x','COMM_ITM_x','COMM_GP_x','COMM_DET_x','ACT_INACT_FL_x','NAICS_CD_x','COMM_DET_y','COMM_GP_y','COMM_DET_y','ACT_INACT_FL_y','NAICS_CD_y','COMM_DSCR_UP_y','DSCR_EXT_DV_y'],axis=1)\n",
    "cr2 = cr.rename(columns={\"KEYWD_x\":\"class\",\"KEYWD_y\":\"commodity\",\"COMM_CD_y\":\"level_1\"})\n",
    "cr2[\"commodity\"]= [row.replace(' ',',')for row in cr2[\"commodity\"]]\n",
    "col4=[\"class\",\"commodity\"]\n",
    "cr2[\"combine\"]= cr2[col4].apply(lambda row: ', '.join(row.values.astype(str)),axis=1)\n"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1= cr2[['class','commodity','level_1']]\n",
    "df2 = df1.append(unspec2,ignore_index=True,sort=False)\n"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>commodity</th>\n",
       "      <th>level_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>RADIO-NAVIGATION-AIRCRAFT</td>\n",
       "      <td>3510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>RADAR-AIRCRAFT</td>\n",
       "      <td>3515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>AIRPLANES</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>AUTOMATIC PILOT SYSTEMS</td>\n",
       "      <td>3525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>BAGGAGE HANDLING EQUIPMENT AND PARTS</td>\n",
       "      <td>3526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>BEACONS, VISUAL AND RUNWAY LIGHTS</td>\n",
       "      <td>3527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>ENGINES AND PARTS-AIRPLANE</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>ENGINES AND PARTS, HELICOPTER</td>\n",
       "      <td>3535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>EQUIPMENT AND SUPPLIES, AIRPLANE</td>\n",
       "      <td>3540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>EQUIPMENT AND SUPPLIES, HELICOPTER</td>\n",
       "      <td>3545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>FLIGHT INSTRUMENTS: AIRSPEED, ALTIMETERS, ATTI...</td>\n",
       "      <td>3546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>FLIGHT SIMULATOR</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>GLIDERS</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>HELICOPTERS</td>\n",
       "      <td>3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>INSTRUMENTS AND TESTERS, HELICOPTER</td>\n",
       "      <td>3565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                class  \\\n",
       "0   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "1   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "2   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "3   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "4   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "5   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "6   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "7   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "8   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "9   AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "10  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "11  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "12  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "13  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "14  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...   \n",
       "\n",
       "                                            commodity level_1  \n",
       "0                           RADIO-NAVIGATION-AIRCRAFT    3510  \n",
       "1                                      RADAR-AIRCRAFT    3515  \n",
       "2                                           AIRPLANES    3520  \n",
       "3                             AUTOMATIC PILOT SYSTEMS    3525  \n",
       "4                BAGGAGE HANDLING EQUIPMENT AND PARTS    3526  \n",
       "5                   BEACONS, VISUAL AND RUNWAY LIGHTS    3527  \n",
       "6                          ENGINES AND PARTS-AIRPLANE    3530  \n",
       "7                       ENGINES AND PARTS, HELICOPTER    3535  \n",
       "8                    EQUIPMENT AND SUPPLIES, AIRPLANE    3540  \n",
       "9                  EQUIPMENT AND SUPPLIES, HELICOPTER    3545  \n",
       "10  FLIGHT INSTRUMENTS: AIRSPEED, ALTIMETERS, ATTI...    3546  \n",
       "11                                   FLIGHT SIMULATOR    3547  \n",
       "12                                            GLIDERS    3548  \n",
       "13                                        HELICOPTERS    3550  \n",
       "14                INSTRUMENTS AND TESTERS, HELICOPTER    3565  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "\n",
    "df1= cr2[['combine','level_1']]\n",
    "df2 = df1.append(unspec2,ignore_index=True,sort=False)\n"
=======
    "df2.head(15)"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combine</th>\n",
       "      <th>level_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             combine level_1\n",
       "0  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3510\n",
       "1  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3515\n",
       "2  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3520\n",
       "3  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3525\n",
       "4  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3526"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df2.apply(lambda x: ','.join(x.astype(str)),axis = 1)"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df2.apply(lambda x: ','.join(x.astype(str)),axis = 1)"
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = pd.DataFrame({'clean':df9})"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 8,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "0    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "1    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "2    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "3    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "4    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
=======
       "                                               clean\n",
       "0  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "1  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "2  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "3  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "4  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU..."
      ]
     },
     "execution_count": 8,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "df9.head()"
=======
    "df_clean2.head()"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent23 = [row.split(',') for row in df_clean2['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = pd.DataFrame({'clean':df9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean\n",
       "0  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "1  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "2  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "3  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "4  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean2.head()"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AIRCRAFT AND AIRPORT', ' EQUIPMENT', ' PARTS', ' AND SUPPLIES', 'RADIO-NAVIGATION-AIRCRAFT', '3510'], ['AIRCRAFT AND AIRPORT', ' EQUIPMENT', ' PARTS', ' AND SUPPLIES', 'RADAR-AIRCRAFT', '3515'], ['AIRCRAFT AND AIRPORT', ' EQUIPMENT', ' PARTS', ' AND SUPPLIES', 'AIRPLANES', '3520'], ['AIRCRAFT AND AIRPORT', ' EQUIPMENT', ' PARTS', ' AND SUPPLIES', 'AUTOMATIC PILOT SYSTEMS', '3525'], ['AIRCRAFT AND AIRPORT', ' EQUIPMENT', ' PARTS', ' AND SUPPLIES', 'BAGGAGE HANDLING EQUIPMENT AND PARTS', '3526']]\n"
     ]
    }
   ],
   "source": [
    "print(sent23[:5])"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 11,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163115\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "sent23 = [row.split(',') for row in df_clean2['clean']]\n"
=======
    "print(len(sent23))"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"'Fresh'\", \" 'cut'\", \" 'amaranthuses'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaranthuses'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'upright'\", \" 'green'\", \" 'amaranthus'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'upright'\", \" 'green'\", \" 'variety'\", \" 'of'\", \" 'amaranthus'\", '10311804'], [\"'Fresh'\", \" 'cut'\", \" 'amaranthuses'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaranthuses'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'upright'\", \" 'red'\", \" 'amaranthus'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'upright'\", \" 'red'\", \" 'variety'\", \" 'of'\", \" 'amaranthus'\", '10311805'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'nan'\", \" '\", \"'\", \" 'nan'\", 'nan'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'naranja'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'naranja'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311901'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'orange'\", \" 'nagano'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'orange'\", \" 'nagano'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311902'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'pygmee'\", \" 'mini'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'pygmee'\", \" 'mini'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311903'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'red'\", \" 'lion'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'red'\", \" 'lion'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311904'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'rilona'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'rilona'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311905'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'royal'\", \" 'velvet'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'royal'\", \" 'velvet'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311906'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'sonatini'\", \" 'orange'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'sonatini'\", \" 'orange'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311907'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'sonatini'\", \" 'red'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'sonatini'\", \" 'red'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311908'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'tango'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'tango'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311909'], [\"'Fresh'\", \" 'cut'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'blooms'\", \" 'of'\", \" 'amaryllises'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'tinto'\", \" 'night'\", \" 'amaryllis'\", \" '\", \"'\", \" 'Fresh'\", \" 'cut'\", \" 'bloom'\", \" 'of'\", \" 'the'\", \" 'tinto'\", \" 'night'\", \" 'variety'\", \" 'of'\", \" 'amaryllises'\", '10311910']]\n"
     ]
    }
   ],
   "source": [
    "print(sent23[10542:10555])"
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.word2vec.Word2Vec(sent23,min_count=1,size=300, workers=6, window= 4,cbow_mean=0)"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 13,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "163115\n"
=======
      "466078\n"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "print(len(sent23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.word2vec.Word2Vec(sent23,min_count=1,size=300, workers=6, window= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51529\n",
      "                                                  combine   level_1\n",
      "6640     'Livestock', ',', 'nan', ',', 'Cats', ',', 'nan'  10101501\n",
      "6641     'Livestock', ',', 'nan', ',', 'Dogs', ',', 'nan'  10101502\n",
      "6642     'Livestock', ',', 'nan', ',', 'Mink', ',', 'nan'  10101504\n",
      "6643     'Livestock', ',', 'nan', ',', 'Rats', ',', 'nan'  10101505\n",
      "6644    'Livestock', ',', 'nan', ',', 'Horses', ',', '...  10101506\n",
      "6645    'Livestock', ',', 'nan', ',', 'Sheep', ',', 'nan'  10101507\n",
      "6646    'Livestock', ',', 'nan', ',', 'Goats', ',', 'nan'  10101508\n",
      "6647    'Livestock', ',', 'nan', ',', 'Asses', ',', 'nan'  10101509\n",
      "6648     'Livestock', ',', 'nan', ',', 'Mice', ',', 'nan'  10101510\n",
      "6649    'Livestock', ',', 'nan', ',', 'Swine', ',', 'nan'  10101511\n",
      "6650    'Livestock', ',', 'nan', ',', 'Rabbits', ',', ...  10101512\n",
      "6651    'Livestock', ',', 'nan', ',', 'Guinea', 'pigs'...  10101513\n",
      "6652    'Livestock', ',', 'nan', ',', 'Primates', ',',...  10101514\n",
      "6653    'Livestock', ',', 'nan', ',', 'Armadillos', ',...  10101515\n",
      "6654    'Livestock', ',', 'nan', ',', 'Cattle', ',', '...  10101516\n",
      "6655    'Livestock', ',', 'nan', ',', 'Camels', ',', '...  10101517\n",
      "6656    'Livestock', ',', 'nan', ',', 'Alpaca', ',', '...  10101518\n",
      "6657    'Livestock', ',', 'nan', ',', 'Buffalo', 'or',...  10101519\n",
      "6658    'Livestock', ',', 'nan', ',', 'Llama', ',', 'T...  10101520\n",
      "6660    'Birds', 'and', 'fowl', ',', 'nan', ',', 'Live...  10101601\n",
      "6662    'Birds', 'and', 'fowl', ',', 'nan', ',', 'Live...  10101603\n",
      "6664    'Birds', 'and', 'fowl', ',', 'nan', ',', 'Live...  10101605\n",
      "6665    'Birds', 'and', 'fowl', ',', 'nan', ',', 'Live...  10101606\n",
      "6668    'Live', 'fish', ',', 'nan', ',', 'Live', 'salm...  10101701\n",
      "6669    'Live', 'fish', ',', 'nan', ',', 'Live', 'trou...  10101702\n",
      "6670    'Live', 'fish', ',', 'nan', ',', 'Live', 'tila...  10101703\n",
      "6671    'Live', 'fish', ',', 'nan', ',', 'Live', 'carp...  10101704\n",
      "6672    'Live', 'fish', ',', 'nan', ',', 'Live', 'eels...  10101705\n",
      "6675    'Live', 'fish', ',', 'nan', ',', 'Live', 'sard...  10101708\n",
      "6676    'Live', 'fish', ',', 'nan', ',', 'Live', 'red'...  10101709\n",
      "...                                                   ...       ...\n",
      "163055  'Agricultural', 'and', 'farming', 'and', 'fish...  95122504\n",
      "163060  'Religious', 'buildings', 'and', 'structures',...  95122603\n",
      "163061  'Religious', 'buildings', 'and', 'structures',...  95122604\n",
      "163064  'Defense', 'buildings', 'and', 'structures', '...  95122701\n",
      "163065  'Defense', 'buildings', 'and', 'structures', '...  95122702\n",
      "163066  'Defense', 'buildings', 'and', 'structures', '...  95122703\n",
      "163073  'Portable', 'commercial', 'and', 'industrial',...  95131601\n",
      "163075  'Portable', 'commercial', 'and', 'industrial',...  95131603\n",
      "163076  'Portable', 'commercial', 'and', 'industrial',...  95131604\n",
      "163078  'Portable', 'commercial', 'and', 'industrial',...  95131606\n",
      "163085  'Prefabricated', 'farm', 'buildings', 'and', '...  95141502\n",
      "163088  'Prefabricated', 'residential', 'buildings', '...  95141602\n",
      "163090  'Prefabricated', 'residential', 'buildings', '...  95141604\n",
      "163091  'Prefabricated', 'residential', 'buildings', '...  95141605\n",
      "163092  'Prefabricated', 'residential', 'buildings', '...  95141606\n",
      "163094  'Prefabricated', 'commercial', 'and', 'industr...  95141701\n",
      "163095  'Prefabricated', 'commercial', 'and', 'industr...  95141702\n",
      "163096  'Prefabricated', 'commercial', 'and', 'industr...  95141703\n",
      "163097  'Prefabricated', 'commercial', 'and', 'industr...  95141704\n",
      "163098  'Prefabricated', 'commercial', 'and', 'industr...  95141705\n",
      "163099  'Prefabricated', 'commercial', 'and', 'industr...  95141706\n",
      "163101  'Prefabricated', 'commercial', 'and', 'industr...  95141708\n",
      "163103  'Prefabricated', 'commercial', 'and', 'industr...  95141710\n",
      "163104  'Prefabricated', 'commercial', 'and', 'industr...  95141711\n",
      "163105  'Prefabricated', 'commercial', 'and', 'industr...  95141712\n",
      "163107  'Prefabricated', 'emergency', 'relief', 'build...  95141801\n",
      "163108  'Prefabricated', 'emergency', 'relief', 'build...  95141802\n",
      "163111  'Prefabricated', 'medical', 'buildings', 'and'...  95141901\n",
      "163112  'Prefabricated', 'medical', 'buildings', 'and'...  95141902\n",
      "163113  'Prefabricated', 'medical', 'buildings', 'and'...  95141903\n",
      "\n",
      "[51529 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def NumberofDocs(li,nums):\n",
    "    shortlist=[]\n",
    "    number=0.0\n",
    "    for i in li:\n",
    "        if(i!='nan'):\n",
    "            point = model2.wv.similarity(str(i),nums)\n",
    "            if(point>0.5):\n",
    "                shortlist.append(i) \n",
    "    \n",
    "    return shortlist\n",
    "\n",
    "result =NumberofDocs(nums,'4045') \n",
    "print(len(result))\n",
    "print(df2.loc[df2['level_1'].isin(result)])"
=======
    "print(len(model2.wv.vocab))"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [combine, level_1]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "result2 =NumberofDocs(nums,'3526') \n",
    "print(len(result2))\n",
    "print(df2.loc[df2['level_1'].isin(result2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
=======
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.03278522"
      ]
     },
     "execution_count": 16,
=======
       "array([ 1.3763489e-03,  8.0989397e-05, -4.9933919e-04,  1.2373235e-03,\n",
       "        9.8903511e-05, -1.5741069e-03,  2.1750461e-03,  2.0561293e-03,\n",
       "        1.2024533e-03, -7.6792872e-04,  1.5806740e-03, -2.0262040e-04,\n",
       "       -2.7390975e-03,  1.1638079e-03,  6.2300131e-04,  2.1982123e-03,\n",
       "        1.4139240e-03,  7.1391161e-04,  6.3139782e-04,  2.7456949e-03,\n",
       "       -7.1329100e-04,  1.0965031e-03, -1.1103353e-03,  2.2138476e-03,\n",
       "        4.1099469e-04, -1.3180485e-04, -1.4843185e-03,  9.0553530e-04,\n",
       "       -1.0013129e-03, -7.5608387e-04, -9.5423107e-04, -4.0916493e-04,\n",
       "        1.4935961e-03,  1.6195103e-04, -5.1696307e-04, -8.4916537e-04,\n",
       "       -3.4861238e-04, -1.9557073e-03,  3.0996281e-04, -6.2820927e-04,\n",
       "       -2.9816678e-05, -1.7754817e-03, -8.6942827e-04, -1.5092905e-03,\n",
       "        2.4752936e-03, -4.8849446e-04,  4.5723579e-04, -2.0021538e-03,\n",
       "        7.4726762e-05,  2.8451661e-05,  2.4617051e-03, -8.0005807e-04,\n",
       "        4.1793747e-04, -5.1428523e-04, -1.6781089e-03, -3.1160023e-05,\n",
       "        1.9271123e-04,  6.6754234e-04, -6.1891356e-04,  3.4477501e-04,\n",
       "        5.7140988e-04, -5.4676255e-04, -1.5119041e-03,  3.9770777e-04,\n",
       "       -4.5332874e-04, -2.5387300e-04,  3.0838992e-04,  2.9491796e-03,\n",
       "        9.2560292e-04,  6.9643266e-04,  9.6890889e-04,  1.3531318e-03,\n",
       "       -1.2288003e-03,  1.7181503e-03,  1.4761125e-03,  2.6618827e-03,\n",
       "        2.5115442e-04, -5.9832295e-04,  8.3967089e-04, -1.5548882e-03,\n",
       "       -1.9300692e-03, -2.4246310e-03, -1.8526970e-03,  2.9853159e-03,\n",
       "       -3.1370900e-04, -5.6344430e-05, -1.0875072e-03,  1.9207443e-04,\n",
       "       -6.8015105e-04, -9.8740158e-04, -4.9151719e-04, -1.2240519e-03,\n",
       "       -1.9468286e-04, -6.3658174e-04, -3.2791337e-05, -1.7633678e-03,\n",
       "       -1.0044281e-03,  1.0406881e-03, -3.1937226e-03, -1.2052217e-03,\n",
       "        1.5026808e-03, -1.3686680e-03, -1.7233846e-03, -6.1667565e-04,\n",
       "        2.0067440e-03, -8.8256355e-05, -1.2803652e-03,  1.9606491e-04,\n",
       "       -1.5570500e-03, -3.0221350e-03,  1.3654132e-03, -1.5699087e-03,\n",
       "       -1.1818870e-03, -5.5064785e-04,  1.2229432e-03,  7.7855715e-04,\n",
       "       -9.5594360e-04,  2.1454878e-03,  1.1029135e-04,  9.9372643e-04,\n",
       "       -1.3772934e-03,  1.2763847e-03,  5.2641268e-04, -3.7993613e-04,\n",
       "       -7.5939094e-04,  2.4402160e-03,  1.7408838e-03,  1.5313808e-03,\n",
       "        1.6532181e-04,  1.5159505e-03,  2.0741355e-03, -1.3039561e-03,\n",
       "       -2.7339591e-04,  2.3456257e-04, -2.1554286e-05,  2.3295739e-05,\n",
       "        1.0690388e-03,  1.2027451e-03, -2.1127330e-03,  1.7462092e-03,\n",
       "       -5.3515466e-04,  2.1420647e-03, -1.2187769e-03,  9.9512818e-04,\n",
       "        2.7383049e-04,  1.0172164e-03,  1.2209947e-03,  3.0273111e-03,\n",
       "       -1.8035608e-03, -7.7682594e-04, -3.7744900e-05,  1.3072101e-03,\n",
       "        1.4062782e-03,  1.3491437e-03, -3.3407458e-04,  6.3672324e-04,\n",
       "       -1.6963435e-04,  8.5497762e-05,  6.5455685e-04, -1.2914100e-04,\n",
       "        1.7736939e-03, -2.2253531e-03, -1.4742636e-04, -2.5660878e-03,\n",
       "       -3.7128862e-03,  1.2209076e-03, -2.7244177e-04,  9.8393671e-04,\n",
       "       -5.2251504e-04,  9.3816122e-04, -2.4371628e-04, -7.6584716e-04,\n",
       "       -6.1590143e-04, -9.4565109e-04, -1.5977485e-04,  6.1912538e-04,\n",
       "       -1.0344686e-03,  7.7898265e-04, -1.8468190e-03, -8.1098417e-04,\n",
       "        4.1331234e-04,  2.3351819e-04,  1.1876895e-03, -1.5513344e-03,\n",
       "        5.4497324e-04, -5.8462244e-04,  4.4236181e-04,  2.8777923e-03,\n",
       "        1.5669024e-03, -3.6926230e-04,  9.7295223e-04, -2.2800777e-03,\n",
       "        8.0585165e-04,  2.1501668e-04, -9.9735691e-05,  5.8742822e-04,\n",
       "        1.0318871e-03,  8.6431281e-04, -7.6356332e-04,  1.4818235e-03,\n",
       "        1.0298433e-03,  5.2695186e-04, -5.3950603e-04, -3.1779069e-04,\n",
       "        1.1945604e-03,  1.9553949e-03,  1.8352686e-03, -6.4219238e-04,\n",
       "        3.6544603e-04, -1.4248949e-03,  1.1759648e-03, -6.0054421e-04,\n",
       "        5.5006189e-05, -1.0266311e-03,  5.7045300e-04,  1.2210276e-03,\n",
       "       -1.9924978e-03, -1.4986405e-04, -1.6227430e-04,  2.3048248e-03,\n",
       "       -8.7122177e-04,  7.5087906e-04,  2.9222571e-04,  5.7812146e-04,\n",
       "       -7.3843636e-04, -1.8027892e-03, -7.5574784e-04, -4.8208464e-04,\n",
       "       -1.9485052e-03, -7.7137456e-04,  1.8392435e-03,  1.2961515e-03,\n",
       "       -1.0798846e-03, -2.6203622e-04,  3.9782780e-04,  1.7159953e-05,\n",
       "       -2.2942103e-03,  1.1823288e-03, -2.0508133e-03,  2.6436066e-03,\n",
       "       -1.0956412e-03,  2.3348662e-03,  8.2112040e-04, -9.9568604e-04,\n",
       "        7.0951349e-04, -8.2762627e-04,  1.0223265e-03,  2.7534894e-03,\n",
       "       -3.0370647e-04,  9.1133988e-04,  1.0066654e-03, -7.6407648e-04,\n",
       "        4.3306660e-04,  1.1255697e-04, -1.2173266e-03, -5.1849679e-04,\n",
       "       -1.5678692e-03, -2.2298556e-03, -3.4434878e-04,  7.2509173e-04,\n",
       "        1.9386386e-03,  8.6609542e-04, -3.0132236e-03, -2.4134858e-04,\n",
       "       -3.7634888e-04, -1.2267838e-03, -7.7314203e-04,  7.9287007e-04,\n",
       "       -1.6840106e-03,  6.8440067e-04, -3.1337555e-04, -1.9467936e-03,\n",
       "       -1.5497522e-03,  1.3136986e-04,  6.7529868e-04,  2.4947134e-05,\n",
       "       -1.0176197e-04, -2.0614658e-03, -2.6880426e-04, -1.4116828e-03,\n",
       "        2.9028242e-03,  3.1744043e-05, -1.3738136e-03, -1.3071545e-03,\n",
       "        1.7107598e-03,  1.3051882e-03,  1.3664090e-03,  1.0043703e-03,\n",
       "       -2.3266720e-04,  1.1328753e-03, -1.4136753e-04, -1.1640707e-03,\n",
       "        1.2905231e-03,  1.3062352e-03, -4.9330998e-04,  2.3370052e-03,\n",
       "        1.8782490e-05, -2.1072838e-03,  2.0312767e-03, -2.4227539e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model2.wv.similarity('10101707','4045')"
=======
    "model2.wv.__getitem__('39101601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def NumberofDocs(li,nums):\n",
    "    shortlist=[]\n",
    "    for i in li:\n",
    "        if(i!='nan'):\n",
    "            point = model2.wv.similarity(str(i),nums)\n",
    "            if(point>.4000001):\n",
    "                shortlist.append(i) \n",
    "    \n",
    "    return shortlist\n",
    "\n",
    "result =NumberofDocs(nums,'4045') \n",
    "print(len(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "result2 =NumberofDocs(nums,'3526') \n",
    "print(len(result2))\n",
    "print(result2)"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "-0.38505948"
=======
       "0.6110741"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model2.wv.similarity('85903723','4045')"
=======
    "model2.wv.similarity('39101601','39101603')"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
<<<<<<< HEAD
   "metadata": {
    "scrolled": true
   },
=======
   "metadata": {},
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[(\" '0RPS47Z'\", 0.9644993543624878),\n",
       " (\" '0RQ03ZZ'\", 0.9606325626373291),\n",
       " (\" '08W083Z'\", 0.959457278251648),\n",
       " ('RIGS', 0.9566643238067627),\n",
       " (\" '0C9WXZ0'\", 0.9555591344833374),\n",
       " (\" 'vinci'\", 0.9531040191650391),\n",
       " (\" 'DW11BBZ'\", 0.9524223804473877),\n",
       " (\" '0TNC7ZZ'\", 0.9520471096038818),\n",
       " (\" '0X020KZ'\", 0.951983630657196),\n",
       " ('17R', 0.9509916305541992)]"
=======
       "0.10373564"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model2.wv.most_similar('3105')[:15]"
=======
    "model2.wv.similarity('10101708','4045')"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
<<<<<<< HEAD
=======
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"  percutaneous endoscopic approach.This surgical intervention or procedure is listed in the World Health Organization's International Statistical Classification of Diseases and Related Health Problems or ICD-10 as code 0S564ZZ\",\n",
       "  0.8030943870544434),\n",
       " (' DIFLUCORTOLONE remains the US FDA Preferred Term for this commodity. Diflucortolone bears US NLM identifiers UMLS ID C0012227 and NCI Concept Code C87231. SMILES: FC12C(C3C(C(C(C3)C)C(=O)CO)(CC1O)C)CC(F)C1=CC(=O)C=CC21C.',\n",
       "  0.7926597595214844),\n",
       " (\"  open approach.This surgical intervention or procedure is listed in the World Health Organization's International Statistical Classification of Diseases and Related Health Problems or ICD-10 as code 04RN0KZ\",\n",
       "  0.7919535040855408),\n",
       " (\"  percutaneous approach.This surgical intervention or procedure is listed in the World Health Organization's International Statistical Classification of Diseases and Related Health Problems or ICD-10 as code 0L5B3ZZ\",\n",
       "  0.7918217182159424),\n",
       " (\"  open approach.This measurement intervention or procedure is listed in the World Health Organization's International Statistical Classification of Diseases and Related Health Problems or ICD-10 as code 4A0104Z\",\n",
       "  0.7866613864898682),\n",
       " (' TREPROSTINIL remains the US FDA Preferred Term for this commodity. Treprostinil bears US NLM identifiers UMLS ID C1145760 and NCI Concept Code C61983. SMILES: OC1C(C2C(C1)Cc1c(C2)cccc1OCC(=O)O)CCC(O)CCCCC.',\n",
       "  0.7847299575805664),\n",
       " ('HOSIERY AND SOCKS', 0.7847282290458679),\n",
       " (\"  percutaneous endoscopic approach.This surgical intervention or procedure is listed in the World Health Organization's International Statistical Classification of Diseases and Related Health Problems or ICD-10 as code 0RWD48Z\",\n",
       "  0.7835137844085693),\n",
       " ('Repirinast This classification denotes a histamine-1 receptor antagonist with the molecular formula C20H21NO5',\n",
       "  0.7832009792327881),\n",
       " ('Domestic pet training kits nan', 0.7814334630966187)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar('3105')[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'\\nbook = open_workbook(\\'UNSPSC English v220601 project.xlsx\\')\\n\\'\\'\\'book = open_workbook(\\'Unspec List2b.xlsx\\')\\'\\'\\'\\n\\'\\'\\'To work on the UNSPSC sheet you need to change the values of 0 to 12 and 1 to\\n16 in order to make the it work.\\'\\'\\'\\ndict_list = []\\nsheet = book.sheet_by_index(0)\\n# read header values into the list\\nkeys = [sheet.cell(0, col_index).value for col_index in range(sheet.ncols)]\\n\\nfor row_index in range(1, sheet.nrows):\\n    d = {keys[col_index]: sheet.cell(row_index, col_index).value\\n         for col_index in range(sheet.ncols)}\\n    dict_list.append(d)\\n\\nprint(len(dict_list))\\n    \\ndoclist =[]\\nlistOfEntry =[]\\nentrylist = []\\ndf7 = pd.DataFrame()\\n\\n\\nfor entry in dict_list:\\n    if(entry.get(\"Family\")==\"\"):\\n        continue\\n    elif(entry.get(\"Family\")!=\"\" and entry.get(\"Class\")==\"\"):\\n        if(listOfEntry!=[]):\\n            #print(listOfEntry)\\n            doclist += entrylist\\n            continue\\n    elif(entry.get(\"Commodity\")==\"\"):\\n        continue\\n    else:\\n        if(entry.get(\"Class Definition\")!=\"\"):\\n            f = str(sent_tokenize(entry.get(\"Class Definition\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n            #print(f)\\n        else:\\n            f=str([\" \"]).strip(\\'[]\\').strip(\\'\\'\\')\\n        e = str(sent_tokenize(entry.get(\"Class Title\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n        #print(e)\\n        g = str(sent_tokenize(entry.get(\"Commodity Title\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n        #print(g)\\n        if(entry.get(\"Commodity Definition\")!=\"\"):\\n            h = str(sent_tokenize(entry.get(\"Commodity Definition\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n            #print(h)\\n        else:\\n            h = str([\" \"]).strip(\\'[]\\').strip(\\'\\'\\')\\n        i=int(entry.get(\"Commodity\"))\\n        df7 = df7.append({\\'class\\':e+f,\\'commodity\\':g+h,\\'level_1\\': i},ignore_index=True)\\n        \\n  \\n        \\ndoclist.append(listOfEntry) \\n\\nprint(\"done\")        \\n\\n\\n\\n\\nmodel2.wv.vocab\\nmodel2.save(\"W2V-Model\")\\n\\ntext = \"AIR CONDITIONING, HEATING, AND VENTILATING: EQUIPMENT, PARTS  HYDRONIC SPECIALTIES\"\\nidt =[\\'101\\'] \\ntext = text.lower()\\nnewEntry = []\\nnewEn =[]\\nstop_words = set(stopwords.words(\\'english\\'))\\nch = [ \\'``\\',\\'``\\', \"\\'\\'\",\\',\\',\\'.\\',\\'\\\\n\\',\"\\'\",\";\",\":\",\"(\",\")\",\"-\",\"--\"]\\n\\n\\nWtest = word_tokenize(text)\\nWtest = [ j for j in Wtest if not j in ch ]\\nWtest = [w for w in Wtest if not w in stop_words]\\nnewEntry.append(Wtest)\\n\\ndef concatenate_list_data(list):\\n    result= \\'\\'\\n    for element in list:\\n        result += str(element+\" \")\\n    return result\\n\\nnewEntry[0] = concatenate_list_data(newEntry[0])\\nnewEntry += idt\\nnewEn.append(newEntry)\\nprint(newEn)\\n\\nnew_mod = gensim.models.Word2Vec.load(\"W2V-Model\")\\nnew_mod.build_vocab(newEn,update = True)\\nnew_mod.train(newEn,total_examples=1,epochs = 1)\\n\\nnew_mod.wv.similarity(\\'30121703.0\\',\\'101\\')\\nnew_mod.wv.most_similar_cosmul(\\'101\\')\\n\\nnew_mod.wv.similar_by_vector(\\'101\\')\\n\\n'"
      ]
     },
     "execution_count": 19,
=======
       "'\\nmodel2.wv.vocab\\nmodel2.save(\"W2V-Model\")\\n\\ntext = \"AIR CONDITIONING, HEATING, AND VENTILATING: EQUIPMENT, PARTS  HYDRONIC SPECIALTIES\"\\nidt =[\\'101\\'] \\ntext = text.lower()\\nnewEntry = []\\nnewEn =[]\\nstop_words = set(stopwords.words(\\'english\\'))\\nch = [ \\'``\\',\\'``\\', \"\\'\\'\",\\',\\',\\'.\\',\\'\\\\n\\',\"\\'\",\";\",\":\",\"(\",\")\",\"-\",\"--\"]\\n\\n\\nWtest = word_tokenize(text)\\nWtest = [ j for j in Wtest if not j in ch ]\\nWtest = [w for w in Wtest if not w in stop_words]\\nnewEntry.append(Wtest)\\n\\ndef concatenate_list_data(list):\\n    result= \\'\\'\\n    for element in list:\\n        result += str(element+\" \")\\n    return result\\n\\nnewEntry[0] = concatenate_list_data(newEntry[0])\\nnewEntry += idt\\nnewEn.append(newEntry)\\nprint(newEn)\\n\\nnew_mod = gensim.models.Word2Vec.load(\"W2V-Model\")\\nnew_mod.build_vocab(newEn,update = True)\\nnew_mod.train(newEn,total_examples=1,epochs = 1)\\n\\nnew_mod.wv.similarity(\\'30121703.0\\',\\'101\\')\\nnew_mod.wv.most_similar_cosmul(\\'101\\')\\n\\nnew_mod.wv.similar_by_vector(\\'101\\')\\n\\n'"
      ]
     },
     "execution_count": 20,
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "book = open_workbook('UNSPSC English v220601 project.xlsx')\n",
    "'''book = open_workbook('Unspec List2b.xlsx')'''\n",
    "'''To work on the UNSPSC sheet you need to change the values of 0 to 12 and 1 to\n",
    "16 in order to make the it work.'''\n",
    "dict_list = []\n",
    "sheet = book.sheet_by_index(0)\n",
    "# read header values into the list\n",
    "keys = [sheet.cell(0, col_index).value for col_index in range(sheet.ncols)]\n",
    "\n",
    "for row_index in range(1, sheet.nrows):\n",
    "    d = {keys[col_index]: sheet.cell(row_index, col_index).value\n",
    "         for col_index in range(sheet.ncols)}\n",
    "    dict_list.append(d)\n",
    "\n",
    "print(len(dict_list))\n",
    "    \n",
    "doclist =[]\n",
    "listOfEntry =[]\n",
    "entrylist = []\n",
    "df7 = pd.DataFrame()\n",
    "\n",
    "\n",
    "for entry in dict_list:\n",
    "    if(entry.get(\"Family\")==\"\"):\n",
    "        continue\n",
    "    elif(entry.get(\"Family\")!=\"\" and entry.get(\"Class\")==\"\"):\n",
    "        if(listOfEntry!=[]):\n",
    "            #print(listOfEntry)\n",
    "            doclist += entrylist\n",
    "            continue\n",
    "    elif(entry.get(\"Commodity\")==\"\"):\n",
    "        continue\n",
    "    else:\n",
    "        if(entry.get(\"Class Definition\")!=\"\"):\n",
    "            f = str(sent_tokenize(entry.get(\"Class Definition\").lower())).strip('[]').strip('\\'')\n",
    "            #print(f)\n",
    "        else:\n",
    "            f=str([\" \"]).strip('[]').strip('\\'')\n",
    "        e = str(sent_tokenize(entry.get(\"Class Title\").lower())).strip('[]').strip('\\'')\n",
    "        #print(e)\n",
    "        g = str(sent_tokenize(entry.get(\"Commodity Title\").lower())).strip('[]').strip('\\'')\n",
    "        #print(g)\n",
    "        if(entry.get(\"Commodity Definition\")!=\"\"):\n",
    "            h = str(sent_tokenize(entry.get(\"Commodity Definition\").lower())).strip('[]').strip('\\'')\n",
    "            #print(h)\n",
    "        else:\n",
    "            h = str([\" \"]).strip('[]').strip('\\'')\n",
    "        i=int(entry.get(\"Commodity\"))\n",
    "        df7 = df7.append({'class':e+f,'commodity':g+h,'level_1': i},ignore_index=True)\n",
    "        \n",
    "  \n",
    "        \n",
    "doclist.append(listOfEntry) \n",
    "\n",
    "print(\"done\")        \n",
<<<<<<< HEAD
    "\n",
    "\n",
    "\n",
    "\n",
=======
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
    "model2.wv.vocab\n",
    "model2.save(\"W2V-Model\")\n",
    "\n",
    "text = \"AIR CONDITIONING, HEATING, AND VENTILATING: EQUIPMENT, PARTS  HYDRONIC SPECIALTIES\"\n",
    "idt =['101'] \n",
    "text = text.lower()\n",
    "newEntry = []\n",
    "newEn =[]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ch = [ '``','``', \"''\",',','.','\\\\n',\"'\",\";\",\":\",\"(\",\")\",\"-\",\"--\"]\n",
    "\n",
    "\n",
    "Wtest = word_tokenize(text)\n",
    "Wtest = [ j for j in Wtest if not j in ch ]\n",
    "Wtest = [w for w in Wtest if not w in stop_words]\n",
    "newEntry.append(Wtest)\n",
    "\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element+\" \")\n",
    "    return result\n",
    "\n",
    "newEntry[0] = concatenate_list_data(newEntry[0])\n",
    "newEntry += idt\n",
    "newEn.append(newEntry)\n",
    "print(newEn)\n",
    "\n",
    "new_mod = gensim.models.Word2Vec.load(\"W2V-Model\")\n",
    "new_mod.build_vocab(newEn,update = True)\n",
    "new_mod.train(newEn,total_examples=1,epochs = 1)\n",
    "\n",
    "new_mod.wv.similarity('30121703.0','101')\n",
    "new_mod.wv.most_similar_cosmul('101')\n",
    "\n",
    "new_mod.wv.similar_by_vector('101')\n",
    "\n",
<<<<<<< HEAD
    "\"\"\""
=======
    "\"\"\"\n"
>>>>>>> 15c60e2d947079db48599ec18e746ac1d2d87bbf
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
