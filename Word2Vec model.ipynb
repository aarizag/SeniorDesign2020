{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from xlrd import open_workbook\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import pprint\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from xlrd import open_workbook\n",
    "import json\n",
    "from gensim import similarities\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "       \n",
    "unspec_df = pd.read_excel('ignore/UNSPSC English v220601 project.xlsx','Sheet1', index_col=None, na_values=['NA'])\n",
    "unspec = unspec_df.drop(['Family Definition','Family','Family Title','Segment Title','Segment Definition','Segment','Version','Key','Synonym','Acronym'],axis = 1)\n",
    "cols = ['Class Title','Class Definition']\n",
    "cols2 =['Commodity Title','Commodity Definition']\n",
    "col3 = ['class','commodity']\n",
    "unspec[\"class\"] = unspec[cols].apply(lambda row: ','.join(row.values.astype(str)), axis=1)\n",
    "unspec[\"commodity\"] = unspec[cols2].apply(lambda row: ','.join(row.values.astype(str)), axis=1)\n",
    "unspec[\"combine\"]= unspec[col3].apply(lambda row: ', '.join(row.values.astype(str)),axis=1)\n",
    "unspec[\"combine\"]=[row.replace('nan','')for row in unspec[\"combine\"]]\n",
    "unspec2 = unspec.drop(['Class','Class Title','Class Definition','Commodity Title','Commodity Definition','class','commodity'],axis=1)\n",
    "unspec2=unspec2.rename(columns={\"Commodity\":\"level_1\"})\n",
    "nums = unspec2['level_1'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df = pd.read_excel('ignore/eCAPS_COMM_11072019.xlsx','COMM_CLS', index_col=None, na_values=['NA'])\n",
    "county_df2 = pd.read_excel('ignore/eCAPS_COMM_11072019.xlsx','COMM_ITM', index_col=None, na_values=['NA'])\n",
    "county_df.drop(['COMM_GP','COMM_DET','ACT_INACT_FL','NAICS_CD'],axis=1)\n",
    "county_df2.drop(['COMM_GP','COMM_DET','ACT_INACT_FL','NAICS_CD'],axis=1)\n",
    "countyresult = pd.merge(county_df,county_df2,on='COMM_CLS')\n",
    "cr = countyresult.drop(['DSCR_EXT_y','DSCR_EXT_DV_x','DSCR_EXT_x','COMM_DSCR_UP_x','COMM_CD_x','COMM_ITM_x','COMM_GP_x','COMM_DET_x','ACT_INACT_FL_x','NAICS_CD_x','COMM_DET_y','COMM_GP_y','COMM_DET_y','ACT_INACT_FL_y','NAICS_CD_y','COMM_DSCR_UP_y','DSCR_EXT_DV_y'],axis=1)\n",
    "cr2 = cr.rename(columns={\"KEYWD_x\":\"class\",\"KEYWD_y\":\"commodity\",\"COMM_CD_y\":\"level_1\"})\n",
    "cr2[\"commodity\"]= [row.replace(' ',',')for row in cr2[\"commodity\"]]\n",
    "col4=[\"class\",\"commodity\"]\n",
    "cr2[\"combine\"]= cr2[col4].apply(lambda row: ', '.join(row.values.astype(str)),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1= cr2[['combine','level_1']]\n",
    "df2 = df1.append(unspec2,ignore_index=True,sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combine</th>\n",
       "      <th>level_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "      <td>3526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             combine level_1\n",
       "0  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3510\n",
       "1  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3515\n",
       "2  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3520\n",
       "3  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3525\n",
       "4  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...    3526"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df2.apply(lambda x: ','.join(x.astype(str)),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "1    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "2    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "3    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "4    AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = pd.DataFrame({'clean':df9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean\n",
       "0  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "1  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "2  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "3  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU...\n",
       "4  AIRCRAFT AND AIRPORT, EQUIPMENT, PARTS, AND SU..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent23 = [row.split(',') for row in df_clean2['clean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Fresh cut amaranthuses', 'Fresh cut blooms of amaranthuses', ' Fresh cut upright green amaranthus', 'Fresh cut bloom of the upright green variety of amaranthus', '10311804'], ['Fresh cut amaranthuses', 'Fresh cut blooms of amaranthuses', ' Fresh cut upright red amaranthus', 'Fresh cut bloom of the upright red variety of amaranthus', '10311805'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' ', '', 'nan'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut naranja amaryllis', 'Fresh cut bloom of the naranja variety of amaryllises', '10311901'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut orange nagano amaryllis', 'Fresh cut bloom of the orange nagano variety of amaryllises', '10311902'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut pygmee mini amaryllis', 'Fresh cut bloom of the pygmee mini variety of amaryllises', '10311903'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut red lion amaryllis', 'Fresh cut bloom of the red lion variety of amaryllises', '10311904'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut rilona amaryllis', 'Fresh cut bloom of the rilona variety of amaryllises', '10311905'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut royal velvet amaryllis', 'Fresh cut bloom of the royal velvet variety of amaryllises', '10311906'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut sonatini orange amaryllis', 'Fresh cut bloom of the sonatini orange variety of amaryllises', '10311907'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut sonatini red amaryllis', 'Fresh cut bloom of the sonatini red variety of amaryllises', '10311908'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut tango amaryllis', 'Fresh cut bloom of the tango variety of amaryllises', '10311909'], ['Fresh cut amaryllises', 'Fresh cut blooms of amaryllises', ' Fresh cut tinto night amaryllis', 'Fresh cut bloom of the tinto night variety of amaryllises', '10311910']]\n"
     ]
    }
   ],
   "source": [
    "print(sent23[10542:10555])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163115\n"
     ]
    }
   ],
   "source": [
    "print(len(sent23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.word2vec.Word2Vec(sent23,min_count=1,size=300, workers=6, window= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47685\n",
      "                                                  combine   level_1\n",
      "6656    Livestock,, Alpaca,The alpaca -from quechua al...  10101518\n",
      "6657    Livestock,, Buffalo or bison,Large, shaggy her...  10101519\n",
      "6661                         Birds and fowl,, Live ducks,  10101602\n",
      "6666    Birds and fowl,, Live guinea fowl,Type of bird...  10101607\n",
      "6672                               Live fish,, Live eels,  10101705\n",
      "6674    Live fish,, Live palometa fish or mylossoma au...  10101707\n",
      "6676    Live fish,, Live red belly pacu fish,A type of...  10101709\n",
      "6678    Live fish,, Live paiche fish,A type of tropica...  10101711\n",
      "6681    Live fish,, Live maparate fish,A type of catfi...  10101714\n",
      "6682    Live fish,, Live lumptail sea robin fish,A typ...  10101715\n",
      "6684    Live fish,, Live ispi fish,A type of pupfish n...  10101717\n",
      "6685    Live fish,, Live frigate tuna fish or melva fi...  10101718\n",
      "6687    Live fish,, Live acarahuazu fish,A tropical fr...  10101720\n",
      "6689    Live fish,, Live armored catfish or carachama,...  10101722\n",
      "6690    Live fish,, Live black prochilodus,A tropical ...  10101723\n",
      "6691    Live fish,, Live blochs catfish,A tropical fre...  10101724\n",
      "6693    Live fish,, Live cabinza grunt,A type of ocean...  10101726\n",
      "6695    Live fish,, Live cascafe fish,A tropical zone ...  10101728\n",
      "6701    Shellfish and aquatic invertebrates,, Live shr...  10101801\n",
      "6708    Shellfish and aquatic invertebrates,, Live squid,  10101808\n",
      "6710    Shellfish and aquatic invertebrates,, Live spo...  10101810\n",
      "6711    Shellfish and aquatic invertebrates,, Live lob...  10101811\n",
      "6720    Insects,, Live southern black widow,A type of ...  10101908\n",
      "6725    Wild animals,, Live bothrops pit viper snake,A...  10102003\n",
      "6726    Wild animals,, Live chironius or vine snake,A ...  10102004\n",
      "6729    Wild animals,, Live epicrates or rainbow boa s...  10102007\n",
      "6731    Wild animals,, Live bushmaster or lachesis sna...  10102009\n",
      "6732    Wild animals,, Live coral or micrurus snake,A ...  10102010\n",
      "6734    Wild animals,, Live philodryas snake,A type of...  10102012\n",
      "6739    Wild animals,, Live monkeys,Monkeys are haplor...  10102017\n",
      "...                                                   ...       ...\n",
      "163025  Hospital buildings and structures,Structures a...  95122003\n",
      "163027  Hospital buildings and structures,Structures a...  95122005\n",
      "163029  Hospital buildings and structures,Structures a...  95122007\n",
      "163032  Accommodation buildings and structures,Buildin...  95122101\n",
      "163035  Accommodation buildings and structures,Buildin...  95122104\n",
      "163036  Accommodation buildings and structures,Buildin...  95122105\n",
      "163042  Sports and health buildings and structures,Bui...  95122304\n",
      "163043  Sports and health buildings and structures,Bui...  95122305\n",
      "163049  Industrial buildings and structures,Buildings ...  95122402\n",
      "163050  Industrial buildings and structures,Buildings ...  95122403\n",
      "163056  Agricultural and farming and fishing buildings...  95122505\n",
      "163058  Religious buildings and structures,Buildings a...  95122601\n",
      "163060  Religious buildings and structures,Buildings a...  95122603\n",
      "163061  Religious buildings and structures,Buildings a...  95122604\n",
      "163062  Religious buildings and structures,Buildings a...  95122605\n",
      "163065  Defense buildings and structures,Buildings or ...  95122702\n",
      "163066  Defense buildings and structures,Buildings or ...  95122703\n",
      "163076  Portable commercial and industrial buildings a...  95131604\n",
      "163078  Portable commercial and industrial buildings a...  95131606\n",
      "163081  Tents and membrane structures,Temporary struct...  95131702\n",
      "163084  Prefabricated farm buildings and structures,Bu...  95141501\n",
      "163092  Prefabricated residential buildings and struct...  95141606\n",
      "163094  Prefabricated commercial and industrial buildi...  95141701\n",
      "163095  Prefabricated commercial and industrial buildi...  95141702\n",
      "163096  Prefabricated commercial and industrial buildi...  95141703\n",
      "163101  Prefabricated commercial and industrial buildi...  95141708\n",
      "163107  Prefabricated emergency relief buildings and s...  95141801\n",
      "163109  Prefabricated emergency relief buildings and s...  95141803\n",
      "163111  Prefabricated medical buildings and structures...  95141901\n",
      "163112  Prefabricated medical buildings and structures...  95141902\n",
      "\n",
      "[47685 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def NumberofDocs(li,nums):\n",
    "    shortlist=[]\n",
    "    number=0.0\n",
    "    for i in li:\n",
    "        if(i!='nan'):\n",
    "            point = model2.wv.similarity(str(i),nums)\n",
    "            if(point>0.8):\n",
    "                shortlist.append(i) \n",
    "    \n",
    "    return shortlist\n",
    "\n",
    "result =NumberofDocs(nums,'4045') \n",
    "print(len(result))\n",
    "print(result)\n",
    "print(df2.loc[df2['level_1'].isin(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "                                                 combine   level_1\n",
      "7012   Residues other than animal feed,, Residue of l...  10152103\n",
      "17226       Earth moving machinery,, Combat earthmovers,  22101534\n",
      "18005  Metal bending machines,Machines that apply dir...  23251504\n",
      "18542  Securing and protecting supplies,, Tamper proo...  24141504\n",
      "18918           Braking systems and components,, Rotors,  25171705\n",
      "19158             Vehicle interior systems,, Headliners,  25174404\n",
      "19536                       Engines,, Pneumatic engines,  26101502\n",
      "19597  Engine components and accessories,, Carburetor...  26101756\n",
      "19743                         Clutches,, Plate clutches,  26111901\n",
      "19950  Exhaust structures or screening equipment,, St...  26131606\n",
      "20109                           Forming tools,, Mallets,  27111601\n",
      "20297  Agriculture, forestry and garden handtools,A s...  27112012\n",
      "20534  Tool attachments and accessories,The comoditie...  27112820\n",
      "20725                     Beams,, Stainless steel beams,  30101705\n",
      "20780                                Plate,, Iron plate,  30102203\n",
      "21016                             Bricks,, Stone bricks,  30131604\n",
      "21945  Machined v process castings,, Zinc v process m...  31121013\n",
      "21993  Machined sand castings,, Lead sand machined ca...  31121215\n",
      "22101  Machined centrifugal castings,, Bronze centrif...  31121712\n",
      "22373         Vacuum moldings,, Plastic vacuum moldings,  31141601\n",
      "22473                               Ropes,, Cotton rope,  31151501\n",
      "22646                                Nuts,, Anchor nuts,  31161701\n",
      "23043                             Gears,, Helical gears,  31171714\n",
      "23076     Abrasives and abrasive media,, Abrasive belts,  31191507\n",
      "23118                     Tape,, Adhesive transfer tape,  31201522\n",
      "23189                 Paints and primers,, Spray paints,  31211507\n",
      "23284  Machined plate stock,, Stainless steel machine...  31231210\n",
      "23598  Machined hydro static extrusions,, Non ferrous...  31291109\n",
      "23603  Machined hydro static extrusions,, Steel machi...  31291114\n",
      "23627  Machined impact extrusions,, Zinc machined imp...  31291217\n",
      "...                                                  ...       ...\n",
      "83895       Machining services,, Flame cutting services,  73181015\n",
      "83933          Forming services,, Roll forming services,  73181203\n",
      "83939      Heat treatment services,, Annealing services,  73181302\n",
      "84000        Nonhazardous waste disposal,, Garbage dump,  76121601\n",
      "84024  Waste incineration services,A service we use w...  76122201\n",
      "84032  Recycling services,, Recycling of computer bas...  76122305\n",
      "84033           Recycling services,, Recycling of paper,  76122306\n",
      "84048    Refuse disposal and treatment fees,, Labor fee,  76122405\n",
      "84083  Environmental advisory services,, Environmenta...  77101706\n",
      "84127  Air pollution,, Air pollution monitoring or me...  77121504\n",
      "84136  Soil pollution,, Polluted soil treatment or re...  77121603\n",
      "84151  Water pollution,, Groundwater pollution monito...  77121707\n",
      "84157     Oil pollution,, Oil spillage control services,  77131502\n",
      "84253  Passenger air transportation,, Sightseeing ser...  78111504\n",
      "84300  General goods storage,, Palletized cargo storage,  78131601\n",
      "84327     Navigational services,, Drawbridge operations,  78141702\n",
      "84464  Temporary personnel services,, Temporary techn...  80111604\n",
      "84641  Trade shows and exhibits,, Talent or entertain...  80141903\n",
      "84844       Computer programmers,, Programming for HTML,  81111603\n",
      "84856  Management information systems MIS,, Wide area...  81111701\n",
      "84902         Internet services,, Internet domain names,  81112107\n",
      "84961  Monetary systems and issues,, Monetary liquidity,  81121604\n",
      "84990  Production planning and control,, Production s...  81141703\n",
      "85149  Editorial and support services,, Editing servi...  82111801\n",
      "85263    Film processing services,, Microfiche services,  82131503\n",
      "85275            Art design services,, Photocomposition,  82141503\n",
      "85338        Oil and gas utilities,, Supply of fuel oil,  83101602\n",
      "85369  Mobile communications services,, Satellite or ...  83111602\n",
      "85552  Pension funds,, Union or guild administered pe...  84131702\n",
      "85775  Funeral and associated services,The services a...  85171501\n",
      "\n",
      "[351 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result2 =NumberofDocs(nums,'3526') \n",
    "print(len(result2))\n",
    "print(df2.loc[df2['level_1'].isin(result2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83012986"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.similarity('10101707','4045')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.similarity('85903723','4045')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' (MILIARIA', 0.9131325483322144),\n",
       " (' WITHOUT COMA K71.10)', 0.9128967523574829),\n",
       " ('11-diol', 0.9126417636871338),\n",
       " ('This classification denotes the group of activities that yields a surgical intervention or procedure to removal of drainage device from retroperitoneum',\n",
       "  0.9125745296478271),\n",
       " (' (OTH DISORDERS RESULTING FROM IMPAIRED RENAL TUBULAR FUNCTION N25.89)',\n",
       "  0.9122788906097412),\n",
       " (' virus not identified', 0.9122744798660278),\n",
       " (' WITH COMA K71.11)', 0.9122116565704346),\n",
       " (' (OTHER VOMITING of NEWBORN P92.9)', 0.9121987819671631),\n",
       " (' (SEPSIS of NEWBORN due to other STREPTOCOCCI P36.19)', 0.9121073484420776),\n",
       " (' UNSPECIFIED L29.3)', 0.9119848012924194)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar('3105')[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbook = open_workbook(\\'UNSPSC English v220601 project.xlsx\\')\\n\\'\\'\\'book = open_workbook(\\'Unspec List2b.xlsx\\')\\'\\'\\'\\n\\'\\'\\'To work on the UNSPSC sheet you need to change the values of 0 to 12 and 1 to\\n16 in order to make the it work.\\'\\'\\'\\ndict_list = []\\nsheet = book.sheet_by_index(0)\\n# read header values into the list\\nkeys = [sheet.cell(0, col_index).value for col_index in range(sheet.ncols)]\\n\\nfor row_index in range(1, sheet.nrows):\\n    d = {keys[col_index]: sheet.cell(row_index, col_index).value\\n         for col_index in range(sheet.ncols)}\\n    dict_list.append(d)\\n\\nprint(len(dict_list))\\n    \\ndoclist =[]\\nlistOfEntry =[]\\nentrylist = []\\ndf7 = pd.DataFrame()\\n\\n\\nfor entry in dict_list:\\n    if(entry.get(\"Family\")==\"\"):\\n        continue\\n    elif(entry.get(\"Family\")!=\"\" and entry.get(\"Class\")==\"\"):\\n        if(listOfEntry!=[]):\\n            #print(listOfEntry)\\n            doclist += entrylist\\n            continue\\n    elif(entry.get(\"Commodity\")==\"\"):\\n        continue\\n    else:\\n        if(entry.get(\"Class Definition\")!=\"\"):\\n            f = str(sent_tokenize(entry.get(\"Class Definition\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n            #print(f)\\n        else:\\n            f=str([\" \"]).strip(\\'[]\\').strip(\\'\\'\\')\\n        e = str(sent_tokenize(entry.get(\"Class Title\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n        #print(e)\\n        g = str(sent_tokenize(entry.get(\"Commodity Title\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n        #print(g)\\n        if(entry.get(\"Commodity Definition\")!=\"\"):\\n            h = str(sent_tokenize(entry.get(\"Commodity Definition\").lower())).strip(\\'[]\\').strip(\\'\\'\\')\\n            #print(h)\\n        else:\\n            h = str([\" \"]).strip(\\'[]\\').strip(\\'\\'\\')\\n        i=int(entry.get(\"Commodity\"))\\n        df7 = df7.append({\\'class\\':e+f,\\'commodity\\':g+h,\\'level_1\\': i},ignore_index=True)\\n        \\n  \\n        \\ndoclist.append(listOfEntry) \\n\\nprint(\"done\")        \\n\\n\\n\\n\\nmodel2.wv.vocab\\nmodel2.save(\"W2V-Model\")\\n\\ntext = \"AIR CONDITIONING, HEATING, AND VENTILATING: EQUIPMENT, PARTS  HYDRONIC SPECIALTIES\"\\nidt =[\\'101\\'] \\ntext = text.lower()\\nnewEntry = []\\nnewEn =[]\\nstop_words = set(stopwords.words(\\'english\\'))\\nch = [ \\'``\\',\\'``\\', \"\\'\\'\",\\',\\',\\'.\\',\\'\\\\n\\',\"\\'\",\";\",\":\",\"(\",\")\",\"-\",\"--\"]\\n\\n\\nWtest = word_tokenize(text)\\nWtest = [ j for j in Wtest if not j in ch ]\\nWtest = [w for w in Wtest if not w in stop_words]\\nnewEntry.append(Wtest)\\n\\ndef concatenate_list_data(list):\\n    result= \\'\\'\\n    for element in list:\\n        result += str(element+\" \")\\n    return result\\n\\nnewEntry[0] = concatenate_list_data(newEntry[0])\\nnewEntry += idt\\nnewEn.append(newEntry)\\nprint(newEn)\\n\\nnew_mod = gensim.models.Word2Vec.load(\"W2V-Model\")\\nnew_mod.build_vocab(newEn,update = True)\\nnew_mod.train(newEn,total_examples=1,epochs = 1)\\n\\nnew_mod.wv.similarity(\\'30121703.0\\',\\'101\\')\\nnew_mod.wv.most_similar_cosmul(\\'101\\')\\n\\nnew_mod.wv.similar_by_vector(\\'101\\')\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "book = open_workbook('UNSPSC English v220601 project.xlsx')\n",
    "'''book = open_workbook('Unspec List2b.xlsx')'''\n",
    "'''To work on the UNSPSC sheet you need to change the values of 0 to 12 and 1 to\n",
    "16 in order to make the it work.'''\n",
    "dict_list = []\n",
    "sheet = book.sheet_by_index(0)\n",
    "# read header values into the list\n",
    "keys = [sheet.cell(0, col_index).value for col_index in range(sheet.ncols)]\n",
    "\n",
    "for row_index in range(1, sheet.nrows):\n",
    "    d = {keys[col_index]: sheet.cell(row_index, col_index).value\n",
    "         for col_index in range(sheet.ncols)}\n",
    "    dict_list.append(d)\n",
    "\n",
    "print(len(dict_list))\n",
    "    \n",
    "doclist =[]\n",
    "listOfEntry =[]\n",
    "entrylist = []\n",
    "df7 = pd.DataFrame()\n",
    "\n",
    "\n",
    "for entry in dict_list:\n",
    "    if(entry.get(\"Family\")==\"\"):\n",
    "        continue\n",
    "    elif(entry.get(\"Family\")!=\"\" and entry.get(\"Class\")==\"\"):\n",
    "        if(listOfEntry!=[]):\n",
    "            #print(listOfEntry)\n",
    "            doclist += entrylist\n",
    "            continue\n",
    "    elif(entry.get(\"Commodity\")==\"\"):\n",
    "        continue\n",
    "    else:\n",
    "        if(entry.get(\"Class Definition\")!=\"\"):\n",
    "            f = str(sent_tokenize(entry.get(\"Class Definition\").lower())).strip('[]').strip('\\'')\n",
    "            #print(f)\n",
    "        else:\n",
    "            f=str([\" \"]).strip('[]').strip('\\'')\n",
    "        e = str(sent_tokenize(entry.get(\"Class Title\").lower())).strip('[]').strip('\\'')\n",
    "        #print(e)\n",
    "        g = str(sent_tokenize(entry.get(\"Commodity Title\").lower())).strip('[]').strip('\\'')\n",
    "        #print(g)\n",
    "        if(entry.get(\"Commodity Definition\")!=\"\"):\n",
    "            h = str(sent_tokenize(entry.get(\"Commodity Definition\").lower())).strip('[]').strip('\\'')\n",
    "            #print(h)\n",
    "        else:\n",
    "            h = str([\" \"]).strip('[]').strip('\\'')\n",
    "        i=int(entry.get(\"Commodity\"))\n",
    "        df7 = df7.append({'class':e+f,'commodity':g+h,'level_1': i},ignore_index=True)\n",
    "        \n",
    "  \n",
    "        \n",
    "doclist.append(listOfEntry) \n",
    "\n",
    "print(\"done\")        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model2.wv.vocab\n",
    "model2.save(\"W2V-Model\")\n",
    "\n",
    "text = \"AIR CONDITIONING, HEATING, AND VENTILATING: EQUIPMENT, PARTS  HYDRONIC SPECIALTIES\"\n",
    "idt =['101'] \n",
    "text = text.lower()\n",
    "newEntry = []\n",
    "newEn =[]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ch = [ '``','``', \"''\",',','.','\\\\n',\"'\",\";\",\":\",\"(\",\")\",\"-\",\"--\"]\n",
    "\n",
    "\n",
    "Wtest = word_tokenize(text)\n",
    "Wtest = [ j for j in Wtest if not j in ch ]\n",
    "Wtest = [w for w in Wtest if not w in stop_words]\n",
    "newEntry.append(Wtest)\n",
    "\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element+\" \")\n",
    "    return result\n",
    "\n",
    "newEntry[0] = concatenate_list_data(newEntry[0])\n",
    "newEntry += idt\n",
    "newEn.append(newEntry)\n",
    "print(newEn)\n",
    "\n",
    "new_mod = gensim.models.Word2Vec.load(\"W2V-Model\")\n",
    "new_mod.build_vocab(newEn,update = True)\n",
    "new_mod.train(newEn,total_examples=1,epochs = 1)\n",
    "\n",
    "new_mod.wv.similarity('30121703.0','101')\n",
    "new_mod.wv.most_similar_cosmul('101')\n",
    "\n",
    "new_mod.wv.similar_by_vector('101')\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
